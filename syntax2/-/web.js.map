{"version":3,"sources":["-","../../mol.ts","../../mol.web.jam.js","../../fail/fail.ts","../syntax2.ts"],"names":[],"mappings":";;AAAA;AACA;AACA;AACA;;;;ACDA,MAAM,CAAC,OAAO,CAAA;;;ADFd;AACA;AACA;;AEFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACXA,IAAU,CAAC,CAUV;AAVD,WAAU,CAAC;IAEV,SAAgB,gBAAgB,CAAE,KAAW;QAC5C,MAAM,KAAK,CAAA;IACZ,CAAC;IAFe,kBAAgB,mBAE/B,CAAA;IAED,SAAgB,SAAS,CAAE,KAAW;QACrC,MAAM,KAAK,CAAA;IACZ,CAAC;IAFe,WAAS,YAExB,CAAA;AAEF,CAAC,EAVS,CAAC,KAAD,CAAC,QAUV;;;;ACVD,IAAU,CAAC,CA8EV;AA9ED,WAAU,CAAC;IAEV,MAAa,YAAY;QAExB,YACQ,MAAe;YAAf,WAAM,GAAN,MAAM,CAAS;YAgBvB,UAAK,GAAG,EAIN,CAAA;YAjBD,KAAK,IAAI,IAAI,IAAI,MAAM,EAAG;gBACzB,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;oBACf,IAAI,EAAG,IAAI;oBACX,MAAM,EAAG,MAAM,CAAE,IAAI,CAAE;oBACvB,IAAI,EAAG,MAAM,CAAE,KAAK,GAAG,MAAM,CAAE,IAAI,CAAE,CAAC,MAAM,CAAE,CAAC,IAAI,CAAE,EAAE,CAAG,CAAC,MAAM,GAAG,CAAC;iBACrE,CAAC,CAAA;aACF;YAED,MAAM,KAAK,GAAG,GAAG,GAAG,IAAI,CAAC,KAAK,CAAC,GAAG,CAAE,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAE,CAAC,IAAI,CAAE,KAAK,CAAE,GAAG,GAAG,CAAA;YACpF,IAAI,CAAC,MAAM,GAAG,MAAM,CAAE,mBAAoB,KAAM,aAAa,EAAG,IAAI,CAAE,CAAA;QAEvE,CAAC;QAUD,QAAQ,CACP,IAAa,EACb,MAAwF;YAGxF,IAAI,GAAG,GAAG,CAAC,CAAA;YAEX,MAAM,EAAG,OAAO,GAAG,GAAG,IAAI,CAAC,MAAM,EAAG;gBAEnC,MAAM,KAAK,GAAG,GAAG,CAAA;gBAEjB,IAAI,CAAC,MAAM,CAAC,SAAS,GAAG,KAAK,CAAA;gBAC7B,IAAI,KAAK,GAAG,IAAI,CAAC,MAAM,CAAC,IAAI,CAAE,IAAI,CAAG,CAAA;gBAErC,GAAG,GAAG,IAAI,CAAC,MAAM,CAAC,SAAS,CAAA;gBAC3B,IAAI,KAAK,KAAK,GAAG;oBAAG,MAAM,IAAI,KAAK,CAAE,aAAa,CAAE,CAAA;gBAEpD,IAAI,MAAM,GAAG,KAAK,CAAE,CAAC,CAAE,CAAA;gBACvB,IAAI,MAAM;oBAAG,MAAM,CAAE,EAAE,EAAG,MAAM,EAAG,EAAE,EAAG,KAAK,CAAE,CAAA;gBAE/C,IAAI,MAAM,GAAG,KAAK,CAAE,CAAC,CAAE,CAAA;gBACvB,IAAI,CAAC,MAAM;oBAAG,SAAQ;gBAEtB,IAAI,MAAM,GAAG,CAAC,CAAA;gBACd,KAAK,IAAI,IAAI,IAAI,IAAI,CAAC,KAAK,EAAG;oBAE7B,IAAI,KAAK,CAAE,MAAM,GAAG,CAAC,CAAE,EAAG;wBACzB,MAAM,CAAE,IAAI,CAAC,IAAI,EAAG,MAAM,EAAG,KAAK,CAAC,KAAK,CAAE,MAAM,EAAE,MAAM,GAAG,IAAI,CAAC,IAAI,CAAE,EAAG,KAAK,GAAG,MAAM,CAAC,MAAM,CAAE,CAAA;wBAChG,SAAS,MAAM,CAAA;qBACf;oBAED,MAAM,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,CAAA;iBACvB;gBAED,EAAA,SAAS,CAAE,IAAI,KAAK,CAAE,wBAAwB,CAAE,CAAE,CAAA;aAElD;QAEF,CAAC;QAED,KAAK,CACJ,IAAa,EACb,QAA6G;YAE7G,IAAI,CAAC,QAAQ,CAAE,IAAI,EAAG,CAAE,IAAI,EAAG,GAAG,IAAI,EAAE,EAAE,CAAC,QAAQ,CAAE,IAAI,CAAE,CAAE,GAAI,IAAI,CAAE,CAAE,CAAA;QAC1E,CAAC;KAED;IA1EY,cAAY,eA0ExB,CAAA;AAEF,CAAC,EA9ES,CAAC,KAAD,CAAC,QA8EV","file":"web.js","sourcesContent":[null,"declare namespace $ {}\nexport = $\nmodule.exports\n",null,"namespace $ {\n\n\texport function $mol_fail_hidden( error : any ) : never {\n\t\tthrow error /// Use 'Never Pause Here' breakpoint in DevTools\n\t}\n\n\texport function $mol_fail( error : any ) : never {\n\t\tthrow error\n\t}\n\n}\n","namespace $ {\n\n\texport class $mol_syntax2< Lexems extends { [ name : string ] : RegExp } > {\n\t\t\n\t\tconstructor(\n\t\t\tpublic lexems : Lexems\n\t\t) {\n\n\t\t\tfor( let name in lexems ) {\n\t\t\t\tthis.rules.push({\n\t\t\t\t\tname : name ,\n\t\t\t\t\tregExp : lexems[ name ] ,\n\t\t\t\t\tsize : RegExp( '^$|' + lexems[ name ].source ).exec( '' )!.length - 1 , \n\t\t\t\t})\n\t\t\t}\n\n\t\t\tconst parts = '(' + this.rules.map( rule => rule.regExp.source ).join( ')|(' ) + ')'\n\t\t\tthis.regexp = RegExp( `([\\\\s\\\\S]*?)(?:(${ parts })|$(?![^]))` , 'gm' ) \n\t\t\t\n\t\t}\n\t\t\n\t\trules = [] as Array<{\n\t\t\tregExp : RegExp ,\n\t\t\tname : string ,\n\t\t\tsize : number\n\t\t}>\n\t\t\n\t\tregexp : RegExp\n\n\t\ttokenize(\n\t\t\ttext : string ,\n\t\t\thandle : ( name : string , found : string , chunks : string[] , offset : number )=> void ,\n\t\t) {\n\t\t\t\n\t\t\tlet end = 0\n\t\t\t\t\n\t\t\tlexing : while( end < text.length ) {\n\n\t\t\t\tconst start = end\n\n\t\t\t\tthis.regexp.lastIndex = start\n\t\t\t\tvar found = this.regexp.exec( text )!\n\t\t\t\t\n\t\t\t\tend = this.regexp.lastIndex\n\t\t\t\tif( start === end ) throw new Error( 'Empty token' )\n\t\t\t\t\n\t\t\t\tvar prefix = found[ 1 ]\n\t\t\t\tif( prefix ) handle( '' , prefix , [] , start )\n\t\t\t\t\n\t\t\t\tvar suffix = found[ 2 ]\n\t\t\t\tif( !suffix ) continue\n\n\t\t\t\tlet offset = 4\n\t\t\t\tfor( let rule of this.rules ) {\n\n\t\t\t\t\tif( found[ offset - 1 ] ) {\n\t\t\t\t\t\thandle( rule.name , suffix , found.slice( offset, offset + rule.size ) , start + prefix.length )\n\t\t\t\t\t\tcontinue lexing\n\t\t\t\t\t}\n\n\t\t\t\t\toffset += rule.size + 1\n\t\t\t\t}\n\n\t\t\t\t$mol_fail( new Error( '$mol_syntax2 is broken' ) )\n\n\t\t\t}\n\n\t\t}\n\t\t\n\t\tparse(\n\t\t\ttext : string ,\n\t\t\thandlers : { [ key in keyof Lexems | '' ] : ( found : string , chunks : string[] , offset : number )=> void } ,\n\t\t) : void {\n\t\t\tthis.tokenize( text , ( name , ...args )=> handlers[ name ]( ... args ) )\n\t\t}\n\n\t}\n\t\n}\n"]}